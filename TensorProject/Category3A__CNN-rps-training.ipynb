{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangHwan-Cha/MyStudy/blob/main/TensorProject/Category3A__CNN-rps-training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCmtzkeGPI2Q"
      },
      "source": [
        "# Category 3\n",
        "\n",
        "Convolution Neural Network (합성곱 신경망)를 활용한 이미지 분류 (Image Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRSKbgK8PRs5"
      },
      "source": [
        "## 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc4QcKvRPSj-"
      },
      "source": [
        "1. GPU 옵션 켜져 있는지 확인할 것!!! (수정 - 노트설정 - 하드웨어설정 (GPU))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPjnA62PXVn"
      },
      "source": [
        "## 순서"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T463L0aPPX_n"
      },
      "source": [
        "1. **import**: 필요한 모듈 import\n",
        "2. **전처리**: 학습에 필요한 데이터 전처리를 수행합니다.\n",
        "3. **모델링(model)**: 모델을 정의합니다.\n",
        "4. **컴파일(compile)**: 모델을 생성합니다.\n",
        "5. **학습 (fit)**: 모델을 학습시킵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Hj9c1NPbPu"
      },
      "source": [
        "## 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcvEYUuhPb3f"
      },
      "source": [
        "For this task you will build a classifier for Rock-Paper-Scissors \n",
        "based on the rps dataset.\n",
        "\n",
        "IMPORTANT: Your final layer should be as shown, do not change the\n",
        "provided code, or the tests may fail\n",
        "\n",
        "IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "So ensure that your input layer is designed accordingly, or the tests\n",
        "may fail. \n",
        "\n",
        "NOTE THAT THIS IS UNLABELLED DATA. \n",
        "You can use the ImageDataGenerator to automatically label it\n",
        "and we have provided some starter code.\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "이 작업에서는 Rock-Paper-Scissors에 대한 분류기를 작성합니다.\n",
        "rps 데이터 셋을 기반으로합니다.\n",
        "\n",
        "중요 : 최종 레이어는 그림과 같아야합니다.\n",
        "\n",
        "중요 : 이미지는 3 바이트 150x150의 컬러사진으로 테스트됩니다.\n",
        "따라서 입력 레이어가 그에 따라 설계되었거나 테스트되었는지 확인하십시오.\n",
        "\n",
        "ImageDataGenerator를 사용하여 자동으로 레이블을 지정할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C3ewm9XQHgr"
      },
      "source": [
        "-----------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4V-b4CYmJjV"
      },
      "source": [
        "## 필요한 모듈 import 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "480D6-GymGYs"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzV-1NNX1LkV"
      },
      "source": [
        "## Dataset 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOOsLCAj1LkW"
      },
      "source": [
        "가위바위보에 대한 손의 사진을 가지고 `가위`인지, `바위`인지, `보자기`인지 분류하는 `classification` 문제입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g1dTl_q1LkX"
      },
      "outputs": [],
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "urllib.request.urlretrieve(url, 'rps.zip')\n",
        "local_zip = 'rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWULnRzA1Lkd"
      },
      "source": [
        "## STEP 2. Define Folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1HQ51J-mT9v"
      },
      "source": [
        "데이터셋의 경로를 지정해 주세요 (root 폴더의 경로를 지정하여야 합니다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFJb6A9z1Lkd"
      },
      "outputs": [],
      "source": [
        "# training dir\n",
        "TRAINING_DIR = \"tmp/rps/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vosdNa0Y1Lkj"
      },
      "source": [
        "## STEP 3. ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrmKimcJ1Lkn"
      },
      "source": [
        "* `rescale`: 이미지의 픽셀 값을 조정\n",
        "* `rotation_range`: 이미지 회전\n",
        "* `width_shift_range`: 가로 방향으로 이동\n",
        "* `height_shift_range`: 세로 방향으로 이동\n",
        "* `shear_range`: 이미지 굴절\n",
        "* `zoom_range`: 이미지 확대\n",
        "* `horizontal_flip`: 횡 방향으로 이미지 반전\n",
        "* `fill_mode`: 이미지를 이동이나 굴절시켰을 때 빈 픽셀 값에 대하여 값을 채우는 방식\n",
        "* `validation_split`: validation set의 구성 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KemaTeRd1Lkp"
      },
      "outputs": [],
      "source": [
        "training_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,   # 값들은 데이터셋을 보고 변경이 필요\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest', \n",
        "    validation_split=0.2\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ZXhFFK1Lkt"
      },
      "source": [
        "## STEP 4. Make Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKWA55pkmjV3"
      },
      "source": [
        "ImageDataGenerator를 잘 만들어 주었다면, `flow_from_directory`로 이미지를 어떻게 공급해 줄 것인가를 지정해 주어야합니다.\n",
        "\n",
        "* train / validation set 전용 generator를 별도로 정의합니다.\n",
        "* `batch_size`를 정의합니다. (32)\n",
        "* `target_size`를 정의합니다. (150 x 150). 이미지를 알아서 타겟 사이즈 만큼 잘라내어 공급합니다.\n",
        "* `class_mode`는 출력층의 **activation**이 `softmax`인 경우 'categorical', `sigmoid`인 경우 'binary'를 지정합니다.\n",
        "* `subset`을 지정합니다. (training / validation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aaAbYk4RqBd"
      },
      "source": [
        "**training_generator**에 대한 `from_from_directory`를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4gbMm121Lk0",
        "outputId": "e19e4268-4ce1-4e79-9851-80cf293a0c50"
      },
      "outputs": [],
      "source": [
        "training_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                          batch_size=32, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          class_mode='categorical', \n",
        "                                                          subset='training',   # subset: 하나의 데이터 셋인 경우에 적용\n",
        "                                                         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R4eLz3N2KBd"
      },
      "source": [
        "**validation_generator**에 대한 `from_from_directory`를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bAYGsIm1aZG",
        "outputId": "a15ad492-fd5d-41d3-d1d7-84e3a539ccec"
      },
      "outputs": [],
      "source": [
        "validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                          batch_size=32, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          class_mode='categorical',\n",
        "                                                          subset='validation', \n",
        "                                                         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEb7eWow2QHJ"
      },
      "source": [
        "504 개의 이미지가 출력되어야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piWUxtwz1Lk4"
      },
      "source": [
        "### 시각화 해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "-Jncc3nu1Lk4",
        "outputId": "4da949c1-5358-46ce-e52a-9c1c708b133c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_map = {\n",
        "    0: 'Paper',\n",
        "    1: 'Rock', \n",
        "    2: 'Scissors'\n",
        "}\n",
        "\n",
        "print('오리지널 사진 파일')\n",
        "\n",
        "original_datagen = ImageDataGenerator(rescale=1./255)\n",
        "original_generator = original_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                          batch_size=128, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          class_mode='categorical'\n",
        "                                                         )\n",
        "\n",
        "for x, y in original_generator:\n",
        "    print(x.shape, y.shape)\n",
        "    print(y[0])\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5)\n",
        "    fig.set_size_inches(15, 6)\n",
        "    for i in range(10):\n",
        "        axes[i//5, i%5].imshow(x[i])\n",
        "        axes[i//5, i%5].set_title(class_map[y[i].argmax()], fontsize=15)\n",
        "        axes[i//5, i%5].axis('off')\n",
        "    plt.show()\n",
        "    break\n",
        "    \n",
        "print('Augmentation 적용한 사진 파일')\n",
        "    \n",
        "for x, y in training_generator:\n",
        "    print(x.shape, y.shape)\n",
        "    print(y[0])\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5)\n",
        "    fig.set_size_inches(15, 6)\n",
        "    for i in range(10):\n",
        "        axes[i//5, i%5].imshow(x[i])\n",
        "        axes[i//5, i%5].set_title(class_map[y[i].argmax()], fontsize=15)\n",
        "        axes[i//5, i%5].axis('off')\n",
        "    \n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-Q-MR9r1LlE"
      },
      "source": [
        "### Convolution Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LtXEsae1LlE"
      },
      "source": [
        "**CNN - activation - Pooling** 과정을 통해 이미지 부분 부분의 **주요한 Feature 들을 추출**해 냅니다.\n",
        "\n",
        "CNN을 통해 우리는 다양한 1개의 이미지를 `filter`를 거친 다수의 이미지로 출력합니다.\n",
        "\n",
        "`filter`의 사이즈는 **3 X 3 필터**를 자주 사용합니다\n",
        "\n",
        "또한, 3 X 3 필터를 거친 이미지의 사이즈는 **2px 만큼 사이즈가 줄어듭니다**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNpNKXkm1LlF"
      },
      "source": [
        "[CNN Filter 예시](https://miro.medium.com/max/1070/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "M7NyN8-81LlG",
        "outputId": "7ba268da-df6b-4fe6-95d1-d6567cb1602c"
      },
      "outputs": [],
      "source": [
        "Image('https://devblogs.nvidia.com/wp-content/uploads/2015/11/fig1.png', width=800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQdDTkZ_1LlU"
      },
      "source": [
        "## 이미지 특성 추출: Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "W2Jen2_11LlR",
        "outputId": "a48f7f43-7954-4c68-f534-e01130c5aacd"
      },
      "outputs": [],
      "source": [
        "for x, y in original_generator:\n",
        "    pic = x[:5]\n",
        "    break\n",
        "    \n",
        "plt.imshow(pic[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq_WZZ8P1LlV"
      },
      "outputs": [],
      "source": [
        "conv2d = Conv2D(64, (3, 3), input_shape=(150, 150, 3))\n",
        "conv2d_activation = Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "vdGaYn091Llb",
        "outputId": "c7851428-0801-4321-b66b-1486ae876bde"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(8, 8)\n",
        "fig.set_size_inches(16, 16)\n",
        "for i in range(64):\n",
        "    axes[i//8, i%8].imshow(conv2d(pic)[0,:,:,i], cmap='gray')\n",
        "    axes[i//8, i%8].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyPRztY21Llo"
      },
      "source": [
        "## 이미지 특성 추출: MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "sHdjvdnw1Llo",
        "outputId": "46ddb5a2-ffad-4081-abe4-c825dff5a3b2"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(8, 8)\n",
        "fig.set_size_inches(16, 16)\n",
        "for i in range(64):\n",
        "    axes[i//8, i%8].imshow(MaxPooling2D(2, 2)(conv2d(pic))[0, :, :, i], cmap='gray')\n",
        "    axes[i//8, i%8].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YekA1ZxNpazk"
      },
      "source": [
        "## 단계별 특성 추출 과정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "0oLNbjvfqpJc",
        "outputId": "493277a3-efef-44b7-fab3-7494c5accf17"
      },
      "outputs": [],
      "source": [
        "conv1 = Conv2D(64, (3, 3), input_shape=(150, 150, 3))(pic)\n",
        "max1 = MaxPooling2D(2, 2)(conv1)\n",
        "conv2 = Conv2D(64, (3, 3))(max1)\n",
        "max2 = MaxPooling2D(2, 2)(conv2)\n",
        "conv3 = Conv2D(64, (3, 3))(max2)\n",
        "max3 = MaxPooling2D(2, 2)(conv3)\n",
        "\n",
        "fig, axes = plt.subplots(4, 1)\n",
        "fig.set_size_inches(6, 12)\n",
        "axes[0].set_title('Original', fontsize=20)\n",
        "axes[0].imshow(pic[0])\n",
        "axes[0].axis('off')\n",
        "axes[1].set_title('Round 1', fontsize=20)\n",
        "axes[1].imshow( conv1[0, :, :, 0], cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[2].set_title('Round 2', fontsize=20)\n",
        "axes[2].imshow( conv2[0, :, :, 0], cmap='gray')\n",
        "axes[2].axis('off')\n",
        "axes[3].set_title('Round 3', fontsize=20)\n",
        "axes[3].imshow( conv3[0, :, :, 0], cmap='gray')\n",
        "axes[3].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfIjG32j1Lls"
      },
      "source": [
        "## 모델 정의 (Sequential)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwj8Q1ZR1Llt"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    # Conv2D, MaxPooling2D 조합으로 층을 쌓습니다. 첫번째 입력층의 input_shape은 (150, 150, 3)으로 지정합니다.\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2), \n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2), \n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2), \n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2), \n",
        "    # 2D -> 1D로 변환을 위하여 Flatten 합니다.\n",
        "    Flatten(), \n",
        "    # 과적합 방지를 위하여 Dropout을 적용합니다.\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    # Classification을 위한 Softmax \n",
        "    # 출력층의 갯수는 클래스의 갯수와 동일하게 맞춰줍니다 (3개), activation도 잊지마세요!\n",
        "    Dense(3, activation='softmax'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw_G-lkR1Llv",
        "outputId": "18923989-d650-44ce-8d0e-6739a03aa76d"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa3EWM7AobvV"
      },
      "source": [
        "## 컴파일 (compile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHQ1abHXK8e9"
      },
      "source": [
        "1. `optimizer`는 가장 최적화가 잘되는 알고리즘인 'adam'을 사용합니다.\n",
        "2. `loss`설정\n",
        "  * 출력층 activation이 `sigmoid` 인 경우: `binary_crossentropy`\n",
        "  * 출력층 activation이 `softmax` 인 경우: \n",
        "    * 원핫인코딩(O): `categorical_crossentropy`\n",
        "    * 원핫인코딩(X): `sparse_categorical_crossentropy`)\n",
        "3. 참고: `ImageDataGenerator`는 자동으로 Label을 **원핫인코딩(one-hot encoding)** 해줍니다.★\n",
        "4. `metrics`를 'acc' 혹은 'accuracy'로 지정하면, 학습시 정확도를 모니터링 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzw3sIaB1Ll0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "# ImageDataGenerator : 자동으로 원핫인코딩을 해주기 때문에 'categorical_crossentropy' 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ0gsuoqSv7z"
      },
      "source": [
        "## ModelCheckpoint: 체크포인트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHmDZ2aSx4O"
      },
      "source": [
        "`val_loss` 기준으로 epoch 마다 최적의 모델을 저장하기 위하여, ModelCheckpoint를 만듭니다.\n",
        "* `checkpoint_path`는 모델이 저장될 파일 명을 설정합니다.\n",
        "* `ModelCheckpoint`을 선언하고, 적절한 옵션 값을 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdgjHzXkoX1b"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"tmp_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820Nfvw81Ll5"
      },
      "source": [
        "## 학습 (fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP7WWv95oIqM"
      },
      "outputs": [],
      "source": [
        "epochs=25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifj14vP71LmA",
        "outputId": "ac835803-9aa6-4fb4-e92e-63f34b1cc440"
      },
      "outputs": [],
      "source": [
        "history = model.fit(training_generator, \n",
        "                    validation_data=(validation_generator),\n",
        "                    epochs=epochs,\n",
        "                    # tensorflow 버전 등 문제가 있을 때 대처법\n",
        "                    # steps_per_epchs=len(training_generator),\n",
        "                    # validation_steps=len(validation_generator),\n",
        "                    callbacks=[checkpoint],\n",
        "                    )\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzhTOjAninH"
      },
      "source": [
        "## 학습 완료 후 Load Weights (ModelCheckpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLqb_6XrMvdq"
      },
      "source": [
        "학습이 완료된 후에는 반드시 `load_weights`를 해주어야 합니다.\n",
        "\n",
        "그렇지 않으면, 열심히 ModelCheckpoint를 만든 의미가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jO1ucZ9ninH",
        "outputId": "0309aac7-a541-459f-c1aa-385e8518ac2d"
      },
      "outputs": [],
      "source": [
        "model.load_weights(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t0xRupR1LmK"
      },
      "source": [
        "## 학습 오차에 대한 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "9r02iNGd1LmL",
        "outputId": "aa99e347-8852-42e4-b510-de8bd29bf249"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(np.arange(1, epochs+1), history.history['acc'])\n",
        "plt.plot(np.arange(1, epochs+1), history.history['loss'])\n",
        "plt.title('Acc / Loss', fontsize=20)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc / Loss')\n",
        "plt.legend(['acc', 'loss'], fontsize=15)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "5f5ffc5f78e6225cd3937f351c2c1563aeb8fb30021449671063618b955d2ad0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
