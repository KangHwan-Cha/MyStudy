{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/KangHwan-Cha/MyStudy/blob/main/TensorProject/Category3C__CNN-new beans-training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153910,"status":"ok","timestamp":1673679464461,"user":{"displayName":"Hwan","userId":"02846878727148454743"},"user_tz":-540},"id":"7hJOExfavKQu","outputId":"d517ea43-5a18-47bc-b72d-64dd6484cdbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","33/33 [==============================] - ETA: 0s - loss: 1.4146 - acc: 0.4836\n","Epoch 1: val_loss improved from inf to 0.74453, saving model to checkpoint_path.ckpt\n","33/33 [==============================] - 30s 432ms/step - loss: 1.4146 - acc: 0.4836 - val_loss: 0.7445 - val_acc: 0.7143\n","Epoch 2/10\n","33/33 [==============================] - ETA: 0s - loss: 0.7089 - acc: 0.6905\n","Epoch 2: val_loss improved from 0.74453 to 0.52428, saving model to checkpoint_path.ckpt\n","33/33 [==============================] - 11s 339ms/step - loss: 0.7089 - acc: 0.6905 - val_loss: 0.5243 - val_acc: 0.7970\n","Epoch 3/10\n","33/33 [==============================] - ETA: 0s - loss: 0.4912 - acc: 0.7969\n","Epoch 3: val_loss improved from 0.52428 to 0.47988, saving model to checkpoint_path.ckpt\n","33/33 [==============================] - 11s 348ms/step - loss: 0.4912 - acc: 0.7969 - val_loss: 0.4799 - val_acc: 0.7820\n","Epoch 4/10\n","33/33 [==============================] - ETA: 0s - loss: 0.4347 - acc: 0.8269\n","Epoch 4: val_loss did not improve from 0.47988\n","33/33 [==============================] - 12s 350ms/step - loss: 0.4347 - acc: 0.8269 - val_loss: 0.5309 - val_acc: 0.7519\n","Epoch 5/10\n","33/33 [==============================] - ETA: 0s - loss: 0.3173 - acc: 0.8810\n","Epoch 5: val_loss improved from 0.47988 to 0.44613, saving model to checkpoint_path.ckpt\n","33/33 [==============================] - 12s 351ms/step - loss: 0.3173 - acc: 0.8810 - val_loss: 0.4461 - val_acc: 0.8346\n","Epoch 6/10\n","33/33 [==============================] - ETA: 0s - loss: 0.2215 - acc: 0.9178\n","Epoch 6: val_loss did not improve from 0.44613\n","33/33 [==============================] - 11s 349ms/step - loss: 0.2215 - acc: 0.9178 - val_loss: 0.4849 - val_acc: 0.8045\n","Epoch 7/10\n","33/33 [==============================] - ETA: 0s - loss: 0.1516 - acc: 0.9478\n","Epoch 7: val_loss improved from 0.44613 to 0.41078, saving model to checkpoint_path.ckpt\n","33/33 [==============================] - 12s 365ms/step - loss: 0.1516 - acc: 0.9478 - val_loss: 0.4108 - val_acc: 0.8346\n","Epoch 8/10\n","33/33 [==============================] - ETA: 0s - loss: 0.1344 - acc: 0.9545\n","Epoch 8: val_loss did not improve from 0.41078\n","33/33 [==============================] - 12s 362ms/step - loss: 0.1344 - acc: 0.9545 - val_loss: 0.4539 - val_acc: 0.8496\n","Epoch 9/10\n","33/33 [==============================] - ETA: 0s - loss: 0.1193 - acc: 0.9555\n","Epoch 9: val_loss did not improve from 0.41078\n","33/33 [==============================] - 12s 356ms/step - loss: 0.1193 - acc: 0.9555 - val_loss: 0.4122 - val_acc: 0.8571\n","Epoch 10/10\n","33/33 [==============================] - ETA: 0s - loss: 0.0666 - acc: 0.9787\n","Epoch 10: val_loss did not improve from 0.41078\n","33/33 [==============================] - 12s 366ms/step - loss: 0.0666 - acc: 0.9787 - val_loss: 0.4278 - val_acc: 0.8496\n"]}],"source":["# ==============================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative to its\n","# difficulty. So your Category 1 question will score significantly\n","# less than your Category 5 question.\n","#\n","# WARNING: Do not use lambda layers in your model, they are not supported\n","# on the grading infrastructure. You do not need them to solve the question.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ==============================================================================\n","#\n","# COMPUTER VISION WITH CNNs\n","#\n","# Create and train a classifier to classify images between three categories\n","# of beans using the beans dataset.\n","# ==============================================================================\n","# ABOUT THE DATASET\n","#\n","# Beans dataset has images belonging to 3 classes as follows:\n","# 2 disease classes (Angular leaf spot, bean rust)\n","# 1 healthy class (healthy).\n","# The images are of different sizes and have 3 channels.\n","# ==============================================================================\n","#\n","# INSTRUCTIONS\n","#\n","# We have already divided the data for training and validation.\n","#\n","# Complete the code in following functions:\n","# 1. preprocess()\n","# 2. solution_model()\n","#\n","# Your code will fail to be graded if the following criteria are not met:\n","# 1. The input shape of your model must be (300,300,3), because the testing\n","#    infrastructure expects inputs according to this specification. You must\n","#    resize all the images in the dataset to this size while pre-processing\n","#    the dataset.\n","# 2. The last layer of your model must be a Dense layer with 3 neurons\n","#    activated by softmax since this dataset has 3 classes.\n","#\n","# HINT: Your neural network must have a validation accuracy of approximately\n","# 0.75 or above on the normalized validation dataset for top marks.\n","#\n","\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Dropout, Flatten, Dense\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","# Use this constant wherever necessary\n","IMG_SIZE = 300\n","\n","# This function normalizes and resizes the images.\n","\n","# COMPLETE THE CODE IN THIS FUNCTION\n","def preprocess(image, label):\n","    # RESIZE YOUR IMAGES HERE (HINT: After resizing the shape of the images\n","    # should be (300, 300, 3).\n","    # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255))\n","    image = tf.image.resize(image, size=(300, 300))\n","    image /= 255\n","    return image, label\n","\n","\n","# This function loads the data, normalizes and resizes the images, splits it into\n","# train and validation sets, defines the model, compiles it and finally\n","# trains the model. The trained model is returned from this function.\n","\n","# COMPLETE THE CODE IN THIS FUNCTION.\n","def solution_model():\n","    # Loads and splits the data into training and validation splits using tfds.\n","    (ds_train, ds_validation), ds_info = tfds.load(\n","        name='beans',\n","        split=['train', 'validation'],\n","        as_supervised=True,\n","        with_info=True)\n","\n","    BATCH_SIZE = 32\n","\n","    # Resizes and normalizes train and validation datasets using the\n","    # preprocess() function.\n","    # Also makes other calls, as evident from the code, to prepare them for\n","    # training.\n","    ds_train = ds_train.map(preprocess).cache().shuffle(\n","        ds_info.splits['train'].num_examples).batch(BATCH_SIZE).prefetch(\n","        tf.data.experimental.AUTOTUNE)\n","    ds_validation = ds_validation.map(preprocess).batch(BATCH_SIZE).cache(\n","\n","    ).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n","    transfer_model.trainable = False\n","\n","    # Code to define the model\n","    model = tf.keras.models.Sequential([\n","        transfer_model,\n","        Flatten(),\n","        Dropout(0.5),\n","        Dense(128, activation='relu'),\n","        Dropout(0.25),\n","        Dense(32, activation='relu'),\n","        tf.keras.layers.Dense(3, activation='softmax'),\n","    ])\n","\n","    # Code to compile and train the model\n","    model.compile(\n","        optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc']\n","    )\n","\n","    checkpoint_path = 'checkpoint_path.ckpt'\n","    checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n","                                save_weights_only=True,\n","                                save_best_only=True,\n","                                monitor='val_loss',\n","                                verbose=1)\n","\n","\n","    model.fit(ds_train,\n","                validation_data=(ds_validation),\n","                epochs=10,\n","                callbacks=[checkpoint]\n","    )\n","    model.load_weights(checkpoint_path)\n","    return model\n","\n","\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"10y2ew6wpIl1ItYipR7PvBldYw8O5lYbG","timestamp":1673677765332}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"5f5ffc5f78e6225cd3937f351c2c1563aeb8fb30021449671063618b955d2ad0"}}},"nbformat":4,"nbformat_minor":0}
